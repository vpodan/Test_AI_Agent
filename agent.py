"""
Simple AI Agent for GitHub
Ğ’ĞµÑ€ÑĞ¸Ñ Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ ÑÑ‚Ğ°Ñ€Ñ‚Ğ° (OpenAI)
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime

from github import Github
from openai import OpenAI

# === Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ===
LOG_DIR = Path("logs")
LOG_DIR.mkdir(exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(LOG_DIR / f"agent_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"),
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger(__name__)


# === Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ===
def resolve_openai_key() -> str:
    """
    ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¾Ğ±Ğ° Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ: OPENAI_API_KEY Ğ¸ OPEN_AI_TOKEN.
    Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ¿ĞµÑ€Ğ²Ğ¾Ğµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾Ğµ.
    """
    key = os.environ.get("OPENAI_API_KEY") or os.environ.get("OPEN_AI_TOKEN")
    if not key:
        raise RuntimeError("OpenAI API key not found. Set OPENAI_API_KEY or OPEN_AI_TOKEN.")
    return key


def resolve_model(name: str | None) -> str:
    """
    ĞĞ»Ğ¸Ğ°Ñ 'codex' Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ñ‚ÑÑ Ğ½Ğ° Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½ÑƒÑ ĞºĞ¾Ğ´Ğ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ OpenAI.
    ĞŸÑ€Ğ¸ Ğ¶ĞµĞ»Ğ°Ğ½Ğ¸Ğ¸ Ğ·Ğ°Ğ¼ĞµĞ½Ğ¸ Ğ½Ğ° gpt-4o-mini Ğ¸Ğ»Ğ¸ gpt-4.1.
    """
    if not name:
        return "gpt-4.1-mini"
    n = name.strip().lower()
    if n in {"codex", "code-davinci", "code-davinci-002"}:
        return "gpt-4.1-mini"  # â† Ğ°Ğ»Ğ¸Ğ°Ñ Ğ¿Ğ¾Ğ´ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ ĞºĞ¾Ğ´Ğ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
    return name


class SimpleGitHubAgent:
    def __init__(self):
        # GitHub
        gh_token = os.environ["GITHUB_TOKEN"]
        repo_name = os.environ["REPO_NAME"]

        self.github = Github(gh_token)
        self.repo = self.github.get_repo(repo_name)

        # OpenAI
        api_key = resolve_openai_key()
        self.openai = OpenAI(api_key=api_key)

        # ĞĞ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ½Ğ¾Ğ¼ĞµÑ€ issue
        self.issue_number = os.environ.get("ISSUE_NUMBER")

        # ĞœĞ¾Ğ´ĞµĞ»ÑŒ (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· ENV MODEL_NAME, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ 'codex')
        self.model_name = resolve_model(os.environ.get("MODEL_NAME", "codex"))

        logger.info(f"ğŸ¤– Agent initialized for: {repo_name}")
        logger.info(f"ğŸ§  Using OpenAI model: {self.model_name}")

    # ==== ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ†Ğ¸ĞºĞ» ====
    def run(self):
        try:
            if self.issue_number:
                issue = self.repo.get_issue(int(self.issue_number))
                self.process_issue(issue)
            else:
                self.process_all_issues()
        except Exception as e:
            logger.error(f"âŒ Error in run(): {e}", exc_info=True)
            raise

    def process_all_issues(self):
        """ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²ÑĞµ open issues Ñ label ai-agent."""
        try:
            label = self.repo.get_label("ai-agent")
        except Exception:
            logger.error("Label 'ai-agent' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½! Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ ĞµĞ³Ğ¾ Ğ² Settings â†’ Labels")
            return

        issues = self.repo.get_issues(state="open", labels=[label])
        count = 0
        for issue in issues:
            if not self.is_processed(issue):
                count += 1
                logger.info(f"ğŸ“‹ Processing issue #{issue.number}")
                self.process_issue(issue)

        if count == 0:
            logger.info("â„¹ï¸ ĞĞµÑ‚ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… issues Ñ Ğ»ĞµĞ¹Ğ±Ğ»Ğ¾Ğ¼ 'ai-agent' Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸.")

    def process_issue(self, issue):
        """ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¾Ğ´Ğ¸Ğ½ issue."""
        try:
            self.comment(issue, "ğŸ¤– AI Agent Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸...")

            logger.info("Analyzing task...")
            analysis = self.analyze_task(issue)
            self.comment(issue, f"**ğŸ“Š ĞĞ½Ğ°Ğ»Ğ¸Ğ·:**\n\n{analysis}")

            logger.info("Generating solution...")
            solution = self.generate_solution(issue, analysis)
            self.comment(
                issue,
                f"**ğŸ’¡ ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµĞ¼Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ:**\n\n{solution}\n\n"
                f"---\n*Ğ­Ñ‚Ğ¾ Ğ´ĞµĞ¼Ğ¾-Ğ²ĞµÑ€ÑĞ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°. ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ ÑĞ¾Ğ·Ğ´Ğ°ÑÑ‚ PR Ñ ĞºĞ¾Ğ´Ğ¾Ğ¼.*",
            )

            logger.info(f"âœ… Issue #{issue.number} processed")
        except Exception as e:
            logger.error(f"Error processing issue #{issue.number}: {e}", exc_info=True)
            self.comment(issue, f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)}")

    # ==== Ğ’Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ Ñ OpenAI ====
    def _chat(self, prompt: str, max_tokens: int = 800) -> str:
        """
        Ğ£Ğ½Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² Chat Completions.
        """
        resp = self.openai.chat.completions.create(
            model=self.model_name,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=max_tokens,
        )
        return resp.choices[0].message.content.strip()

    def analyze_task(self, issue):
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ."""
        prompt = f"""ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ´Ğ»Ñ Python-Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°.

Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº: {issue.title}
ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: {issue.body or 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾'}

Ğ”Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (2-3 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ):
- Ğ§Ñ‚Ğ¾ Ğ½ÑƒĞ¶Ğ½Ğ¾ ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ
- ĞšĞ°ĞºĞ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹/Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ Ğ·Ğ°Ñ‚Ñ€Ğ¾Ğ½ÑƒÑ‚Ñ‹
- ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ°Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ (Ğ½Ğ¸Ğ·ĞºĞ°Ñ/ÑÑ€ĞµĞ´Ğ½ÑÑ/Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ) Ğ¸ Ñ€Ğ¸ÑĞºĞ¸
"""
        return self._chat(prompt, max_tokens=500)

    def generate_solution(self, issue, analysis):
        """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ."""
        prompt = f"""ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸.

Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ°: {issue.title}
{issue.body or ''}

ĞĞ½Ğ°Ğ»Ğ¸Ğ·: {analysis}

ĞĞ°Ğ¿Ğ¸ÑˆĞ¸:
1) ĞŸĞ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ»Ğ°Ğ½ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ (Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ°Ñ‚Ğ¾Ğ¼Ğ°Ñ€Ğ½Ñ‹Ğµ ÑˆĞ°Ğ³Ğ¸)
2) ĞšĞ°ĞºĞ¾Ğ¹ ĞºĞ¾Ğ´ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ/Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ (ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ)
3) ĞšĞ°ĞºĞ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ/Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ
4) ĞĞ°Ğ±Ğ¾Ñ€ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ¾Ğ² (ĞºÑ€Ğ°Ñ‚ĞºĞ¾)
"""
        return self._chat(prompt, max_tokens=900)

    # ==== GitHub ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ ====
    def comment(self, issue, text: str):
        issue.create_comment(text)
        logger.info(f"ğŸ’¬ Comment added to issue #{issue.number}")

    def is_processed(self, issue) -> bool:
        for comment in issue.get_comments():
            if "ğŸ¤– AI Agent Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·" in comment.body:
                return True
        return False


def main():
    logger.info("=" * 50)
    logger.info("ğŸš€ GitHub AI Agent Starting")
    logger.info("=" * 50)

    try:
        agent = SimpleGitHubAgent()
        agent.run()
        logger.info("âœ… Agent finished successfully")
    except Exception as e:
        logger.error(f"âŒ Agent failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
